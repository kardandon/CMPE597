{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_aVanGLsOF_"
   },
   "outputs": [],
   "source": [
    "from math import floor\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import exp\n",
    "from numpy.random import shuffle\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.datasets import cifar10\n",
    "from skimage.transform import resize\n",
    "from numpy import asarray\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "FOLDER = \"./Data/\"\n",
    "\n",
    "VAE_MODEL = FOLDER + \"Vae_model_dict_50EPOCHS_v2\"\n",
    "DIGIT_SAVE_DIR_GAN_BCE = FOLDER + 'sample_digits_GAN_BCE.png'\n",
    "DIGIT_SAVE_DIR_GAN_WASSERSTEIN = FOLDER + 'sample_digits_GAN_Wasserstein.png'\n",
    "DIGIT_SAVE_DIR_VAE = FOLDER + 'sample_digits.png'\n",
    "G_BCE = FOLDER + \"Generator_200epochsBCE\"\n",
    "G_WASSERSTEIN = FOLDER + \"Generator_200epochsWasserstein\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "z_dim = 4\n",
    "z = torch.randn(100, z_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ot9Gq6Px-d5",
    "outputId": "7c132fd3-f593-4041-92ea-40b5c0c5e5cd"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim, loss_function):\n",
    "        super(VAE, self).__init__()\n",
    "        self.loss_function = loss_function\n",
    "        self.zdim = z_dim\n",
    "        # encoder part\n",
    "        self.lstm1 = nn.LSTM(input_size=x_dim, hidden_size=h_dim1)\n",
    "        self.fc31 = nn.Linear(h_dim1, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim1, z_dim)\n",
    "        # decoder part\n",
    "        self.tconv2d1 = nn.ConvTranspose2d(1, 32, 8)\n",
    "        self.tconv2d2 = nn.ConvTranspose2d(32, 16, 4)\n",
    "        self.tconv2d3 = nn.ConvTranspose2d(16, 8, 2)\n",
    "        self.fc2 = nn.Linear(h_dim2, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h, hidden = self.lstm1(x)\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = torch.reshape(z, (-1, 1, int(math.sqrt(self.zdim)), int(math.sqrt(self.zdim)),))\n",
    "        h = F.relu(self.tconv2d1(h))\n",
    "        #h = torch.nn.functional.dropout(h, p=0.8)\n",
    "        h = F.relu(self.tconv2d2(h))\n",
    "        #h = torch.nn.functional.dropout(h, p=0.8)\n",
    "        h = F.relu(self.tconv2d3(h))\n",
    "        #h = torch.nn.functional.dropout(h, p=0.8)\n",
    "        h = torch.flatten(h, start_dim=1)\n",
    "        return F.sigmoid(self.fc2(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "    \n",
    "    def train_data(self, epoch, train_loader):\n",
    "        self.train()\n",
    "        train_loss = 0\n",
    "        train_kld = 0\n",
    "        loss_history = []\n",
    "        KLD_history = []\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            recon_batch, mu, log_var = vae(data)\n",
    "            loss, KLD= self.loss_function(recon_batch, data, mu, log_var)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            train_kld += KLD.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "        \n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))\n",
    "        return train_loss / len(train_loader.dataset), train_kld / len(train_loader.dataset)\n",
    "    \n",
    "    def test_data(self, test_loader):\n",
    "        self.eval()\n",
    "        test_loss= 0\n",
    "        kld_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for data, _ in test_loader:\n",
    "                data = data.to(device)\n",
    "                recon, mu, log_var = vae(data)\n",
    "                \n",
    "                # sum up batch loss\n",
    "                loss, kld = self.loss_function(recon, data, mu, log_var)\n",
    "                test_loss += loss.item()\n",
    "                kld_loss += kld.item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        kld_loss /= len(test_loader.dataset)\n",
    "        print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "        return test_loss, kld_loss\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1= 128, h_dim2=1352, z_dim=z_dim, loss_function=nn.BCELoss())\n",
    "vae.load_state_dict(torch.load(VAE_MODEL, map_location=device))\n",
    "\n",
    "with torch.no_grad():\n",
    "    VAE_images = vae.decoder(z).to(device).view(100, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_uuy7yfyojv"
   },
   "outputs": [],
   "source": [
    "LOSS = \"BCE\"\n",
    "WCL = 0.01\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, g_input_dim, g_output_dim):\n",
    "        super(Generator, self).__init__()       \n",
    "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, g_output_dim)\n",
    "    \n",
    "    def forward(self, x): \n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return torch.tanh(self.fc4(x))\n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d_input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        if LOSS == \"BCE\":\n",
    "            return torch.sigmoid(self.fc4(x))\n",
    "        elif LOSS == \"Wasserstein\":\n",
    "            return (self.fc4(x))\n",
    "z_dim = 4\n",
    "mnist_dim = 28 * 28\n",
    "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
    "G.load_state_dict(torch.load(G_BCE, map_location=device))\n",
    "with torch.no_grad():\n",
    "    BCE_images = G(z).view(100, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4N74CoG1K-d"
   },
   "outputs": [],
   "source": [
    "LOSS = \"Wasserstein\"\n",
    "WCL = 0.01\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, g_input_dim, g_output_dim):\n",
    "        super(Generator, self).__init__()       \n",
    "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, g_output_dim)\n",
    "    \n",
    "    def forward(self, x): \n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return torch.tanh(self.fc4(x))\n",
    "  \n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, d_input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "    \n",
    "    # forward method\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = F.dropout(x, 0.2)\n",
    "        if LOSS == \"BCE\":\n",
    "            return torch.sigmoid(self.fc4(x))\n",
    "        elif LOSS == \"Wasserstein\":\n",
    "            return (self.fc4(x))\n",
    "z_dim = 4\n",
    "mnist_dim = 28 * 28\n",
    "G = Generator(g_input_dim = z_dim, g_output_dim = mnist_dim).to(device)\n",
    "G.load_state_dict(torch.load(G_WASSERSTEIN, map_location=device))\n",
    "with torch.no_grad():\n",
    "    WASSERSTEIN_images = G(z).view(100, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypPACZvQs2Hr",
    "outputId": "54986994-f0b6-4d44-80be-80adbcd308fd"
   },
   "outputs": [],
   "source": [
    "# REF: https://machinelearningmastery.com/how-to-implement-the-inception-score-from-scratch-for-evaluating-generated-images/ \n",
    "# scale an array of images to a new size\n",
    "def scale_images(images, new_shape):\n",
    "  images_list = list()\n",
    "  for image in images:\n",
    "    # resize with nearest neighbor interpolation\n",
    "    new_image = resize(image, new_shape, 0)\n",
    "    # store\n",
    "    images_list.append(new_image)\n",
    "  return asarray(images_list)\n",
    "\n",
    "# assumes images have any shape and pixels in [0,255]\n",
    "def calculate_inception_score(images, n_split=10, eps=1E-16):\n",
    "  # load inception v3 model\n",
    "  model = InceptionV3()\n",
    "  images = images.cpu().detach().numpy()\n",
    "  # enumerate splits of images/predictions\n",
    "  scores = list()\n",
    "  n_part = floor(images.shape[0] / n_split)\n",
    "  for i in range(n_split):\n",
    "    # retrieve images\n",
    "    ix_start, ix_end = i * n_part, (i+1) * n_part\n",
    "    subset = images[ix_start:ix_end]\n",
    "    # convert from uint8 to float32\n",
    "    subset = subset.astype('float32')\n",
    "    # scale images to the required size\n",
    "    subset = scale_images(subset, (299,299,3))\n",
    "    # pre-process images, scale to [-1,1]\n",
    "    subset = preprocess_input(subset)\n",
    "    # predict p(y|x)\n",
    "    p_yx = model.predict(subset)\n",
    "    # calculate p(y)\n",
    "    p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "    # calculate KL divergence using log probabilities\n",
    "    kl_d = p_yx * (log(p_yx + eps) - log(p_y + eps))\n",
    "    # sum over classes\n",
    "    sum_kl_d = kl_d.sum(axis=1)\n",
    "    # average over images\n",
    "    avg_kl_d = mean(sum_kl_d)\n",
    "    # undo the log\n",
    "    is_score = exp(avg_kl_d)\n",
    "    # store\n",
    "    scores.append(is_score)\n",
    "    # average across images\n",
    "  is_avg, is_std = mean(scores), std(scores)\n",
    "  return is_avg, is_std\n",
    "\n",
    "print(\"VAE Inception Score: \")\n",
    "is_avg, is_std = calculate_inception_score(VAE_images)\n",
    "print(f\"mean: {is_avg} std: {is_std}\")\n",
    "\n",
    "print(\"GAN BCE Inception Score: \")\n",
    "is_avg, is_std = calculate_inception_score(BCE_images)\n",
    "print(f\"mean: {is_avg} std: {is_std}\")\n",
    "\n",
    "print(\"WGAN Inception Score: \")\n",
    "is_avg, is_std = calculate_inception_score(WASSERSTEIN_images)\n",
    "print(f\"mean: {is_avg} std: {is_std}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
